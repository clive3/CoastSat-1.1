{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EO4SD SHORELINE CHANGE MAPPING AND FORECASTING\n",
    "\n",
    "This code has been modifed by Carpenter (2020) for the project Earth Observation for Sustainable Development. Below demonstrates an example processing workflow for Benin and Togo's Coastline between 2000-2020.\n",
    "\n",
    "This software is based on scripts and code developed by:\n",
    "* Vos K., Splinter K.D., Harley M.D., Simmons J.A., Turner I.L. (2019). CoastSat: a Google Earth Engine-enabled Python toolkit to extract shorelines from publicly available satellite imagery. Environmental Modelling and Software. 122, 104528. https://doi.org/10.1016/j.envsoft.2019.104528\n",
    "\n",
    "It enables the users to extract time-series of shoreline change over the last 20+ years at their site of interest.\n",
    "There are three main steps:\n",
    "1. Retrieval of median composite satellite images of the region of interest from Google Earth Engine\n",
    "2. Shoreline extraction at sub-pixel resolution\n",
    "\n",
    "## Initial settings\n",
    "\n",
    "Refer to the Set-up and Installation section of the User Handbook for instructions on how to install the Python packages necessary to run the software, including Google Earth Engine Python API. See original methodology via https://github.com/kvos/CoastSat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\cneil\\Anaconda3\\envs\\coastsat-1.1\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\cneil\\Anaconda3\\envs\\coastsat-1.1\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\cneil\\Anaconda3\\envs\\coastsat-1.1\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from coastsat import NOC_tools, NOC_shoreline, NOC_download,\\\n",
    "    SDS_tools, SDS_shoreline, SDS_download, SDS_preprocess\n",
    "\n",
    "settings ={'cloud_thresh':0.9,\n",
    "           'output_epsg': 3857,\n",
    "           \n",
    "            # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "            'min_beach_area': 4500,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "            'buffer_size': 150,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "            'min_length_sl': 200,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "            'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    \n",
    "            # Sentinel\n",
    "            'CLOUD_FILTER': 50,         # [Integer] Maximum image cloud cover percent allowed in image collection'\n",
    "            'CLD_PRB_THRESH': 25,       # {Integer] Cloud probability (%); values greater than are considered cloud\n",
    "            'NIR_DRK_THRESH': 0.08,     # [Float] Near-infrared reflectance; values less than are considered potential cloud shadow\n",
    "            'CLD_PRJ_DIST': 2,          # [Float] Maximum distance (km) to search for cloud shadows from cloud edges |\n",
    "            'BUFFER': 50,               # [Integer] Distance (m) to dilate the edge of cloud-identified objects |\n",
    "\n",
    "            'reference_shoreline': True,\n",
    "            'max_dist_ref': 100,        # max distance (in meters) allowed from the reference shoreline\n",
    "          \n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval of the images from GEE\n",
    "\n",
    "To retrieve from the GEE server the available satellite images cropped around the user-defined region of coastline for the particular time period of interest, the following variables are required:\n",
    "\n",
    "* Coordinate list: a list of the coordinates of the region of interest (longitude/latitude pairs in WGS84) â€“ see section 'create coordinate list in User handbook to extract ROI from study site\n",
    "* all_dates: dates over which the images will be retrieved (e.g., dates = ['2017-12-01', '2018-01-01'])\n",
    "* all_sats: satellite missions to consider (e.g., sat_list = ['L7', 'L8', 'S2'] for Landsat 7, 8 and Sentinel-2 collections)\n",
    "* sitename: name of the site (this is the name of the subfolder where the images and other accompanying files will be stored)\n",
    "\n",
    "Similar to coastsat, there are some extra parameters such as those to go through manual checking, whether to combine Landsat collections and cloud thresholds.\n",
    "\n",
    "Make sure the area of your ROI is smaller than 100 km2 (if larger split it into smaller ROIs) - GEE limits download size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ArgyleAirport\n"
     ]
    }
   ],
   "source": [
    "# directory where the data will be accessed and stored\n",
    "dataPartition = 'c:\\\\data\\\\coastsat'\n",
    "country = 'STV'\n",
    "base_filepath = os.path.join(dataPartition, country)  \n",
    "\n",
    "# filepaths etc\n",
    "filepath_sites = os.path.join(base_filepath, 'sites')\n",
    "sites = os.listdir(filepath_sites)\n",
    "\n",
    "sat_name = 'S2'\n",
    "\n",
    "dates = ['2020-01-01', '2020-12-31']\n",
    "\n",
    "for site in sites:\n",
    "\n",
    "    kml_filepath = os.path.join(filepath_sites, site)\n",
    "    kml_polygon = NOC_tools.polygon_from_kml(kml_filepath)\n",
    "    roi_polygon = SDS_tools.smallest_rectangle(kml_polygon)\n",
    "    \n",
    "    sitename = site[:site.find('.')]\n",
    "\n",
    "    inputs = {'polygon': roi_polygon, 'dates': dates, 'sat_list': [sat_name],\n",
    "              'sitename': sitename, 'filepath': base_filepath}\n",
    "    \n",
    "    settings['inputs'] = inputs\n",
    "    \n",
    "    print(f'Processing: {sitename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished ...\n"
     ]
    }
   ],
   "source": [
    "    ## download median images\n",
    "#    metadata = NOC_download.retrieve_median_image(settings)\n",
    "#    metadata = SDS_download.get_metadata(inputs)\n",
    "    \n",
    "    print('finished ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S2': {'filenames': ['2020-01-01-00-00-00_S2_ArgyleAirport_median_10m.tif'], 'acc_georef': [1.0], 'epsg': [4326], 'dates': [datetime.datetime(2020, 1, 1, 0, 0, tzinfo=<UTC>)]}}\n"
     ]
    }
   ],
   "source": [
    "    ## load saved metadata\n",
    "    metadata = SDS_download.get_metadata(settings['inputs'])\n",
    "    \n",
    "    print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SDS_preprocess.save_jpg(metadata, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference shoreline already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "settings['reference_shoreline'] = SDS_preprocess.get_reference_sl(metadata, settings)\n",
    "settings['max_dist_ref'] = 100 # max distance (in meters) allowed from the reference shoreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping shorelines:\n",
      "S2:   100%\n",
      "\n",
      "\n",
      "finished ...\n"
     ]
    }
   ],
   "source": [
    "    %matplotlib qt\n",
    "    \n",
    "    ##Batch shoreline detection\n",
    "    output = NOC_shoreline.extract_shorelines(metadata, settings)\n",
    "    \n",
    "    print('finished ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicates\n",
      "0 bad georef\n"
     ]
    }
   ],
   "source": [
    "output = SDS_tools.remove_duplicates(output) # removes duplicates (images taken on the same date by the same satellite)\n",
    "output = SDS_tools.remove_inaccurate_georef(output, 10) # remove inaccurate georeferencing (set threshold to 10 m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished ...\n"
     ]
    }
   ],
   "source": [
    "geomtype = 'lines' # choose 'points' or 'lines' for the layer geometry\n",
    "gdf = SDS_tools.output_to_gdf(output, geomtype)\n",
    "gdf.crs = {'init':'epsg:'+str(settings['output_epsg'])} # set layer projection\n",
    "# save GEOJSON layer to file\n",
    "gdf.to_file(os.path.join(inputs['filepath'], inputs['sitename'], '%s_output_%s.geojson'%(sitename,geomtype)),\n",
    "                                driver='GeoJSON', encoding='utf-8')\n",
    "\n",
    "print('finished ...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
