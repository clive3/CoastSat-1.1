{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EO4SD SHORELINE CHANGE MAPPING AND FORECASTING\n",
    "\n",
    "This code has been modifed by Carpenter (2020) for the project Earth Observation for Sustainable Development. Below demonstrates an example processing workflow for Benin and Togo's Coastline between 2000-2020.\n",
    "\n",
    "This software is based on scripts and code developed by:\n",
    "* Vos K., Splinter K.D., Harley M.D., Simmons J.A., Turner I.L. (2019). CoastSat: a Google Earth Engine-enabled Python toolkit to extract shorelines from publicly available satellite imagery. Environmental Modelling and Software. 122, 104528. https://doi.org/10.1016/j.envsoft.2019.104528\n",
    "\n",
    "It enables the users to extract time-series of shoreline change over the last 20+ years at their site of interest.\n",
    "There are three main steps:\n",
    "1. Retrieval of median composite satellite images of the region of interest from Google Earth Engine\n",
    "2. Shoreline extraction at sub-pixel resolution\n",
    "\n",
    "## Initial settings\n",
    "\n",
    "Refer to the Set-up and Installation section of the User Handbook for instructions on how to install the Python packages necessary to run the software, including Google Earth Engine Python API. See original methodology via https://github.com/kvos/CoastSat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.print_utils import printProgress, printWarning\n",
    "from coastsat import NOC_tools, NOC_shoreline, NOC_download, NOC_preprocess, \\\n",
    "    SDS_tools, SDS_shoreline, SDS_download, SDS_preprocess\n",
    "\n",
    "settings ={'output_epsg': 32620,\n",
    "           \n",
    "           'cloud_thresh':0.9,\n",
    "           \n",
    "            # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "            'min_beach_area': 4500,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "            'buffer_size': 150,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "            'min_length_sl': 200,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "            'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    " \n",
    "            ## Image download Parameters\\n\",\n",
    "            # Landsat\\n\",\n",
    "            'LCloudScore': 15,         # Mean cloud score threshold (include images with less then threshold)\\n\",\n",
    "            'add_L7_to_L5': True,      # Add Landsat 7 to Landsat 5 median composite if they are in same time period\\n\",\n",
    "            'add_L5_to_L7': True,      # Add Landsat 5 to Landsat 7 median composite if they are in same time period\\n\",\n",
    "            'add_L7_to_L8': False,      # Add Landsat 7 to Landsat 8 median composite if they are in same time period\\n\",\n",
    "            'LCloudThreshold': 35,     # Pixels from a single image in a collection larger than this cloud score threshold\\n\",\n",
    "                                       # will be masked.\\n\",\n",
    "            'sand_color': '',\n",
    "           \n",
    "           'coregistration': False,\n",
    "           \n",
    "            # Sentinel\n",
    "            'CLOUD_FILTER': 50,         # [Integer] Maximum image cloud cover percent allowed in image collection'\n",
    "            'CLD_PRB_THRESH': 25,       # {Integer] Cloud probability (%); values greater than are considered cloud\n",
    "            'NIR_DRK_THRESH': 0.08,     # [Float] Near-infrared reflectance; values less than are considered potential cloud shadow\n",
    "            'CLD_PRJ_DIST': 2,          # [Float] Maximum distance (km) to search for cloud shadows from cloud edges |\n",
    "            'BUFFER': 50,               # [Integer] Distance (m) to dilate the edge of cloud-identified objects |\n",
    "\n",
    "            'reference_shoreline': True,\n",
    "            'max_dist_ref': 100,        # max distance (in meters) allowed from the reference shoreline\n",
    "   \n",
    "           # labels for classes for the classifier and colours for display\n",
    "           'classes':{'hard': [1, [1, 0, 0]], 'nature': [2, [0, 1, 0]],\n",
    "                      'urban': [3, [1, 1, 0]], 'white-water': [4, [1, 0, 1]],\n",
    "                      'water': [5, [0, 0.4, 1]], 'sand': [6, [1, 0.6, 0]]},\n",
    "           \n",
    "            'bands': {'L8': {'pan': [['B8'],15],\n",
    "                             'ms':  [['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'BQA'], 30]},\n",
    "                      'S2': {'10m': [['B2', 'B3', 'B4', 'B8'], 10],\n",
    "                             '20m': [['B5', 'B6', 'B7', 'B8A', 'B11', 'B12'], 20],\n",
    "                             '60m': [['B12'], 60]}, }\n",
    "          }\n",
    "# directory where the data will be accessed and stored\n",
    "data_partition = 'c:\\\\data\\\\coastsat'\n",
    "country = 'UK'\n",
    "base_dir_path = os.path.join(data_partition, country)  \n",
    "sites_dir_path = os.path.join(base_dir_path, 'sites')\n",
    "sites = os.listdir(sites_dir_path)\n",
    "\n",
    "dates = [['2019-01-01', '2019-06-30'],\n",
    "         ['2019-07-01', '2019-12-31'],\n",
    "         ['2020-01-01', '2020-06-30'],\n",
    "         ['2020-07-01', '2020-12-31']]\n",
    "\n",
    "inputs = {'sat_name': 'S2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download optical data from GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in sites:\n",
    "    for date_pair in dates:\n",
    "\n",
    "        kml_filepath = os.path.join(sites_dir_path, site)\n",
    "        kml_polygon = NOC_tools.polygon_from_kml(kml_filepath)\n",
    "        roi_polygon = SDS_tools.smallest_rectangle(kml_polygon)\n",
    "\n",
    "        site_name = site[:site.find('.')]\n",
    "        median_dir_path = os.path.join(base_dir_path, site_name, 'median')\n",
    "        inputs['site_name'] = site_name\n",
    "        inputs['dates'] = date_pair \n",
    "        inputs['median_dir_path'] = median_dir_path\n",
    "        settings['inputs'] = inputs\n",
    "        \n",
    "        printProgress(f'processing {site_name}: {date_pair}')\n",
    "        \n",
    "        NOC_download.retrieve_median_optical(settings)\n",
    "    \n",
    "metadata = NOC_download.save_metadata(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find reference threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress  >>>  processing Weymouth\n",
      "progress  >>>  file_names loaded\n",
      "progress  >>>  displaying reference histogram\n",
      "@@@ MNDWI min: -0.8505577802711499\n",
      "@@@ MNDWI max: 0.6108129772317995\n",
      "progress  >>>  shoreline extracted\n"
     ]
    }
   ],
   "source": [
    "inputs['pansharpen'] = False\n",
    "inputs['reference_threshold'] = 0\n",
    "inputs['dates'] = ['2019-01-01', '2020-12-31']\n",
    "    \n",
    "for site in sites:\n",
    "    \n",
    "    site_name = site[:site.find('.')]\n",
    "    median_dir_path = os.path.join(base_dir_path, site_name, 'median')\n",
    "    inputs['site_name'] = site_name\n",
    "    inputs['median_dir_path'] = median_dir_path\n",
    "    settings['inputs'] = inputs\n",
    "    \n",
    "    printProgress(f'processing {site_name}')\n",
    "    \n",
    "    %matplotlib qt\n",
    "    NOC_shoreline.find_reference_threshold(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract shorelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress  >>>  processing Weymouth: ['2019-01-01', '2019-06-30']\n",
      "progress  >>>  metadata loaded\n",
      "{'file_names': ['Weymouth_median_S2019-01-01_E2019-06-30_10m.txt', 'Weymouth_median_S2019-01-01_E2019-06-30_20m.txt', 'Weymouth_median_S2019-01-01_E2019-06-30_60m.txt'], 'epsg': 4326, 'date_start': '2019-01-01', 'date_end': '2019-06-30', 'number_images': 29}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'S2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6b8dd6cf3906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'qt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNOC_shoreline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_shoreline_optical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\code\\CoastSat-1.1\\coastsat\\NOC_shoreline.py\u001b[0m in \u001b[0;36mextract_shoreline_optical\u001b[1;34m(metadata, settings)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mpixel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mband_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mbase_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msat_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodels_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'classification'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'S2'"
     ]
    }
   ],
   "source": [
    "inputs = {'sat_name': sat_name}\n",
    "\n",
    "inputs['create_reference_shoreline'] = True \n",
    "inputs['pansharpen'] = True\n",
    "inputs['reference_threshold'] = -0.25\n",
    "        \n",
    "for site in sites:\n",
    "    for date_pair in dates:\n",
    " \n",
    "        site_name = site[:site.find('.')]\n",
    "        median_dir_path = os.path.join(base_dir_path, site_name, 'median')\n",
    "        inputs['site_name'] = site_name\n",
    "        inputs['dates'] = date_pair \n",
    "        inputs['median_dir_path'] = median_dir_path\n",
    "        settings['inputs'] = inputs\n",
    "\n",
    "        printProgress(f'processing {site_name}: {date_pair}')\n",
    "        \n",
    "        metadata = NOC_download.load_metadata(settings)\n",
    "        print(metadata)\n",
    "        \n",
    "        %matplotlib qt\n",
    "        output = NOC_shoreline.extract_shoreline_optical(metadata, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = NOC_tools.output_to_gdf(output, 'lines')\n",
    "\n",
    "satname = output['satname'][0]\n",
    "file_string = f'{sitename}_shorelines_{satname}.geojson'\n",
    "\n",
    "gdf.crs = {'init':'epsg:'+str(settings['output_epsg'])} # set layer projection\n",
    "# save GEOJSON layer to file\n",
    "gdf.to_file(os.path.join(inputs['filepath'], inputs['sitename'],\n",
    "                         file_string),\n",
    "                         driver='GeoJSON', encoding='utf-8')\n",
    "print('finished ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,8])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output['shorelines'])):\n",
    "    sl = output['shorelines'][i]\n",
    "    date = output['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.', label=date.strftime('%d-%m-%Y'))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
